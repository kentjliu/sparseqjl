{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51HftXqlaBMT"
      },
      "source": [
        "# SparseQJL Demo\n",
        "This is a notebook which you can follow to run the same experiments we did. For experiments with Llama models, we recommend using an `A100` runtime for sufficient RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JLFrIgiGP-AB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q datasets\n",
        "!pip install -q transformers\n",
        "!pip install triton\n",
        "!pip install flash_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1xxUyt8-QFVj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/kentjliu/sparseqjl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnTMn-Q1QHuA",
        "outputId": "25da90b7-c60a-4b2a-e32f-3ffc99c38b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/sparseqjl\n"
          ]
        }
      ],
      "source": [
        "%cd sparseqjl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5BvUkOGb2liQ"
      },
      "outputs": [],
      "source": [
        "# Set up your Huggingface Token here to load models, For llama models, you need to request to access from Meta first.\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"YOUR_HUGGINGFACE_TOKEN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw8JgyIu3Hks"
      },
      "source": [
        "## Build kernels (~5 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q8tYqp1PkVDq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python qjl_kernel/setup.py build_ext --inplace --build-temp=./qjl_kernel/build --build-lib=./qjl_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Tyv1BeZjQZ"
      },
      "source": [
        "Ensure kernels are built in the correct directory. The following files should show:\n",
        "* `cuda_qjl_gqa_score.cpython-310-x86_64-linux-gnu.so*`\n",
        "* `cuda_qjl_quant.cpython-310-x86_64-linux-gnu.so*  `\n",
        "* `cuda_qjl_score.cpython-310-x86_64-linux-gnu.so*`\n",
        "* `quantization.cpython-310-x86_64-linux-gnu.so*`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZe1MFGvkR2Q",
        "outputId": "08ad1d22-5872-479b-d6c5-7a8184ff063b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbuild\u001b[0m/                                               matmul.py\n",
            "\u001b[01;34mcsrc\u001b[0m/                                                new_pack.py\n",
            "\u001b[01;32mcuda_qjl_gqa_score.cpython-310-x86_64-linux-gnu.so\u001b[0m*  qjl_kernel.py\n",
            "\u001b[01;32mcuda_qjl_quant.cpython-310-x86_64-linux-gnu.so\u001b[0m*      \u001b[01;32mquantization.cpython-310-x86_64-linux-gnu.so\u001b[0m*\n",
            "\u001b[01;32mcuda_qjl_score.cpython-310-x86_64-linux-gnu.so\u001b[0m*      setup.py\n"
          ]
        }
      ],
      "source": [
        "%ls qjl_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyTwXstvBOp6"
      },
      "source": [
        "## Test SparseQJL on Llama\n",
        "Params:\n",
        "\n",
        "* `model_name`: String denoting HuggingFace Llama model path to test. Default: `meta-llama/Llama-2-7b-hf`\n",
        "* `qjl`: Boolean flag denoting whether or not to apply QJL.\n",
        "* `sparsity`: Float between 0 and 1 denoting \\% uniform sparsity with SparseGPT. Default: `0.0`\n",
        "* `wbits`: Int denoting the bit-width for weight quantization. We suggest using a value of `4`. Default: `16` (No quant)\n",
        "* `dtype`: String denoting standard datatype of model. Options are `float16` and `float32`. Default: `float16`.\n",
        "\n",
        "Note:\n",
        "* `meta-llama/Llama-2-7b-hf`: takes about 20 minutes to run with pruning\n",
        "* `meta-llama/Llama-2-13b-hf`: takes about 35 minutes to run with pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU85hko9QO4u",
        "outputId": "1df1b112-a1e0-4498-e13f-14dbfe37592d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-21 02:53:41.418481: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-21 02:53:41.436308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 02:53:41.457902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 02:53:41.464421: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 02:53:41.479677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 02:53:42.725808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 609/609 [00:00<00:00, 4.25MB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.55MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 65.4MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.40MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 19.8MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 85.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:51, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:48, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:56, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:55, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.98G [00:00<00:51, 193MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:55, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:50, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:01<00:48, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 241M/9.98G [00:01<00:46, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:01<00:45, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.98G [00:01<00:44, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:01<00:45, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 367M/9.98G [00:01<00:44, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.98G [00:01<00:43, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 430M/9.98G [00:02<00:43, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:02<00:50, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 493M/9.98G [00:02<00:47, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:02<00:46, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 545M/9.98G [00:02<00:50, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:02<00:48, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:03<00:44, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 640M/9.98G [00:03<00:43, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:03<00:43, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 703M/9.98G [00:03<00:46, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:03<00:44, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 765M/9.98G [00:03<00:44, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 786M/9.98G [00:03<00:51, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 807M/9.98G [00:04<00:49, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:04<00:46, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 870M/9.98G [00:04<00:44, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:04<00:42, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:04<00:41, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:04<00:40, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:04<00:39, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:04<00:39, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:05<00:38, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:05<00:39, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:05<00:43, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:05<00:42, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:05<00:42, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:05<00:47, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:06<00:45, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:06<00:45, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:06<00:47, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.32G/9.98G [00:06<00:43, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.35G/9.98G [00:06<00:41, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:06<00:42, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:06<00:41, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:07<00:39, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:07<00:38, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:07<00:38, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:07<00:39, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:07<00:38, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:07<00:39, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:07<00:38, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:08<00:37, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:08<00:36, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:08<00:38, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.75G/9.98G [00:08<00:37, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:08<00:37, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:08<00:42, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:08<00:41, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:09<00:39, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:09<00:37, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:09<00:37, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.96G/9.98G [00:09<00:37, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.99G/9.98G [00:09<00:37, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.02G/9.98G [00:09<00:37, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.06G/9.98G [00:09<00:39, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:10<00:37, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:10<00:36, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:10<00:35, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.18G/9.98G [00:10<00:34, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.21G/9.98G [00:10<00:34, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.24G/9.98G [00:10<00:34, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:10<00:35, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:11<00:35, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.34G/9.98G [00:11<00:34, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:11<00:33, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:11<00:33, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.43G/9.98G [00:11<00:32, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:11<00:32, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:11<00:33, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.53G/9.98G [00:12<00:40, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.56G/9.98G [00:12<00:37, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:12<00:36, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:12<00:35, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:12<00:36, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:12<00:34, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:12<00:32, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:13<00:33, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:13<00:32, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:13<00:33, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:13<00:36, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:13<00:39, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:13<00:36, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.92G/9.98G [00:13<00:36, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:14<00:34, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:14<00:35, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.00G/9.98G [00:14<00:34, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:14<00:32, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.06G/9.98G [00:14<00:33, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:14<00:33, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:14<00:31, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:15<00:31, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:15<00:31, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:15<00:30, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:15<00:29, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:15<00:29, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:15<00:29, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:15<00:28, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:16<00:29, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:16<00:28, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:16<00:28, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:16<00:27, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:16<00:27, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:16<00:27, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:16<00:27, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:16<00:27, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.62G/9.98G [00:17<00:27, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:17<00:27, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.68G/9.98G [00:17<00:26, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:17<00:28, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:17<00:27, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:17<00:27, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:17<00:26, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:18<00:27, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:18<00:29, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:18<00:28, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:18<00:27, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:18<00:27, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:18<00:26, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:18<00:25, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:19<00:25, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:19<00:25, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:19<00:24, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:19<00:24, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:19<00:24, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:19<00:24, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:19<00:24, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:20<00:24, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:20<00:24, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:20<00:23, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:20<00:23, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:20<00:23, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:20<00:23, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:20<00:23, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:20<00:23, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:21<00:23, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:21<00:22, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:21<00:22, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:21<00:22, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:21<00:22, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:21<00:22, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:21<00:22, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:21<00:22, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:22<00:23, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:22<00:26, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.83G/9.98G [00:22<00:25, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.87G/9.98G [00:22<00:24, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.90G/9.98G [00:22<00:23, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.93G/9.98G [00:22<00:23, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:22<00:22, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.99G/9.98G [00:23<00:21, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:23<00:22, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:23<00:25, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [00:23<00:24, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:23<00:24, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.14G/9.98G [00:23<00:22, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.17G/9.98G [00:24<00:22, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.20G/9.98G [00:24<00:22, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.23G/9.98G [00:24<00:22, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [00:24<00:24, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.30G/9.98G [00:24<00:22, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.33G/9.98G [00:24<00:21, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:24<00:20, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.39G/9.98G [00:25<00:20, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.42G/9.98G [00:25<00:19, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:25<00:25, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.48G/9.98G [00:25<00:22, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:25<00:21, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:25<00:20, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.58G/9.98G [00:25<00:19, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.61G/9.98G [00:26<00:19, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.64G/9.98G [00:26<00:18, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.67G/9.98G [00:26<00:23, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:26<00:21, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.74G/9.98G [00:26<00:20, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:26<00:19, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:26<00:18, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:27<00:18, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:27<00:17, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [00:27<00:22, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:27<00:20, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:27<00:19, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:27<00:18, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [00:28<00:17, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:28<00:17, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:28<00:21, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:28<00:20, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.14G/9.98G [00:28<00:18, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:28<00:17, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:28<00:17, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:29<00:16, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [00:29<00:16, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.30G/9.98G [00:29<00:19, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.33G/9.98G [00:29<00:18, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [00:29<00:17, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.40G/9.98G [00:29<00:16, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.43G/9.98G [00:30<00:16, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.46G/9.98G [00:30<00:15, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.49G/9.98G [00:30<00:14, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.52G/9.98G [00:30<00:18, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [00:30<00:17, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:30<00:16, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.62G/9.98G [00:30<00:15, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.65G/9.98G [00:31<00:14, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.68G/9.98G [00:31<00:14, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [00:31<00:17, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:31<00:16, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [00:31<00:15, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.81G/9.98G [00:31<00:14, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.84G/9.98G [00:31<00:13, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.87G/9.98G [00:32<00:19, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.89G/9.98G [00:32<00:18, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:32<00:19, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:32<00:16, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:32<00:15, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:32<00:14, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:33<00:13, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:33<00:12, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:33<00:12, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [00:33<00:12, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:33<00:12, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.98G [00:33<00:11, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:33<00:11, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.98G [00:33<00:11, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.29G/9.98G [00:34<00:11, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [00:34<00:11, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:34<00:13, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [00:34<00:12, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:34<00:11, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [00:34<00:11, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:34<00:10, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [00:35<00:10, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:35<00:10, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.57G/9.98G [00:35<00:13, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:35<00:12, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:35<00:10, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:35<00:10, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:36<00:10, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:36<00:09, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:36<00:12, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:36<00:11, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [00:36<00:10, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:36<00:09, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.89G/9.98G [00:36<00:09, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:37<00:09, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [00:37<00:09, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:37<00:10, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:37<00:09, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:37<00:09, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:37<00:08, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:37<00:08, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:38<00:07, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [00:38<00:07, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.20G/9.98G [00:38<00:09, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.23G/9.98G [00:38<00:09, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.26G/9.98G [00:38<00:08, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [00:38<00:07, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [00:39<00:07, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [00:39<00:07, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:39<00:08, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.42G/9.98G [00:39<00:07, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [00:39<00:07, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.48G/9.98G [00:39<00:06, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:39<00:06, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.55G/9.98G [00:40<00:06, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [00:40<00:06, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.61G/9.98G [00:40<00:07, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:40<00:06, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [00:40<00:06, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.70G/9.98G [00:40<00:05, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [00:40<00:05, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:41<00:05, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.80G/9.98G [00:41<00:05, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [00:41<00:06, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [00:41<00:05, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:41<00:05, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [00:41<00:04, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [00:42<00:04, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [00:42<00:04, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:42<00:05, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.98G [00:42<00:04, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.08G/9.98G [00:42<00:05, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:42<00:04, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [00:43<00:04, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [00:43<00:04, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:43<00:03, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [00:43<00:03, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [00:43<00:03, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [00:43<00:03, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [00:43<00:02, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [00:43<00:02, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [00:44<00:02, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:44<00:02, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [00:44<00:02, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:44<00:02, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:44<00:02, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [00:44<00:01, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [00:44<00:01, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.60G/9.98G [00:45<00:01, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [00:45<00:01, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [00:45<00:01, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [00:45<00:01, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [00:45<00:01, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [00:45<00:00, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:46<00:00, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:46<00:00, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:46<00:00, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:46<00:00, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:46<00:00, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [00:46<00:00, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:46<00:00, 213MB/s]\n",
            "Downloading shards:  50% 1/2 [00:47<00:47, 47.15s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:12, 269MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:13, 252MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:00<00:14, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:13, 248MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 157M/3.50G [00:00<00:13, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 189M/3.50G [00:00<00:13, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 220M/3.50G [00:01<00:18, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 252M/3.50G [00:01<00:17, 190MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 283M/3.50G [00:01<00:15, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:01<00:20, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 346M/3.50G [00:01<00:18, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 377M/3.50G [00:01<00:16, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:02<00:15, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 440M/3.50G [00:02<00:14, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 472M/3.50G [00:02<00:13, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 503M/3.50G [00:02<00:13, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 535M/3.50G [00:02<00:12, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:02<00:12, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 598M/3.50G [00:02<00:12, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 629M/3.50G [00:03<00:13, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:03<00:12, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 692M/3.50G [00:03<00:12, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 724M/3.50G [00:03<00:12, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 755M/3.50G [00:03<00:11, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 786M/3.50G [00:03<00:11, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 818M/3.50G [00:03<00:11, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:04<00:14, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 881M/3.50G [00:04<00:13, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:04<00:12, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:04<00:11, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 975M/3.50G [00:04<00:11, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:04<00:10, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.04G/3.50G [00:04<00:10, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:05<00:13, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:05<00:12, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.13G/3.50G [00:05<00:11, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.16G/3.50G [00:05<00:10, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.20G/3.50G [00:05<00:10, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:05<00:09, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.26G/3.50G [00:06<00:12, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:06<00:11, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.32G/3.50G [00:06<00:10, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:06<00:09, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.38G/3.50G [00:06<00:09, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:06<00:09, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.45G/3.50G [00:06<00:08, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:07<00:11, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:07<00:10, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:07<00:09, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:07<00:08, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:07<00:08, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:07<00:08, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:07<00:07, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:08<00:09, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:08<00:09, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:08<00:08, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:08<00:07, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:08<00:07, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:08<00:07, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:09<00:08, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.92G/3.50G [00:09<00:08, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.95G/3.50G [00:09<00:07, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:09<00:07, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.01G/3.50G [00:09<00:06, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:09<00:06, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:09<00:06, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:10<00:07, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:10<00:07, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:10<00:06, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:10<00:06, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:10<00:05, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:10<00:05, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.30G/3.50G [00:10<00:05, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:11<00:06, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:11<00:05, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:11<00:05, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:11<00:04, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:11<00:04, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:11<00:04, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:12<00:05, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:12<00:04, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:12<00:04, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:12<00:05, 156MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:12<00:04, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:12<00:04, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:12<00:04, 189MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:13<00:03, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:13<00:03, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:13<00:03, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:13<00:03, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:13<00:02, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:13<00:02, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:13<00:02, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:14<00:02, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:14<00:02, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:14<00:02, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:14<00:01, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:14<00:01, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:14<00:01, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:15<00:01, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:15<00:01, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:15<00:01, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:15<00:01, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:15<00:01, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:15<00:00, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:15<00:00, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:16<00:00, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:16<00:00, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:16<00:00, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.46G/3.50G [00:16<00:00, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:16<00:00, 211MB/s]\n",
            "Downloading shards: 100% 2/2 [01:04<00:00, 32.14s/it]\n",
            "LlamaForCausalLM_QJL has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From v4.50 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "`LlamaRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.21s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.42MB/s]\n",
            "Model and tokenizer for meta-llama/Llama-2-7b-hf are set up successfully.\n",
            "Starting pruning...\n",
            "Ready to prune.\n",
            "Pruning layer 0...\n",
            "0 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.73\n",
            "error 2340.764892578125\n",
            "0 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 2067.4052734375\n",
            "0 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 158.89846801757812\n",
            "0 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 4.127501487731934\n",
            "0 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 2731.919921875\n",
            "0 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 2638.86279296875\n",
            "0 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.70\n",
            "error 21.895292282104492\n",
            "Pruning layer 1...\n",
            "1 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 6493.3369140625\n",
            "1 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 6657.57666015625\n",
            "1 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 751.81494140625\n",
            "1 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 66.29769134521484\n",
            "1 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 11998.19921875\n",
            "1 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 10575.044921875\n",
            "1 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.67\n",
            "error 9307.84765625\n",
            "Pruning layer 2...\n",
            "2 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 33258.6484375\n",
            "2 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 31067.025390625\n",
            "2 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 11244.486328125\n",
            "2 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 129.00021362304688\n",
            "2 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 31028.033203125\n",
            "2 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.73\n",
            "error 26781.3125\n",
            "2 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.78\n",
            "error 517.0977783203125\n",
            "Pruning layer 3...\n",
            "3 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 111347.4453125\n",
            "3 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 102246.859375\n",
            "3 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 34689.15625\n",
            "3 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 210.38528442382812\n",
            "3 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 60083.078125\n",
            "3 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 51394.03125\n",
            "3 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.67\n",
            "error 1061.08984375\n",
            "Pruning layer 4...\n",
            "4 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 118822.5\n",
            "4 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 108376.3515625\n",
            "4 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 37647.09765625\n",
            "4 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 545.05810546875\n",
            "4 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 86693.578125\n",
            "4 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.72\n",
            "error 70788.8125\n",
            "4 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.72\n",
            "error 2133.162841796875\n",
            "Pruning layer 5...\n",
            "5 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 133608.921875\n",
            "5 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 133367.015625\n",
            "5 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 44202.5234375\n",
            "5 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 830.243408203125\n",
            "5 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 108280.015625\n",
            "5 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 88194.703125\n",
            "5 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.74\n",
            "error 3135.3251953125\n",
            "Pruning layer 6...\n",
            "6 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 185671.34375\n",
            "6 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 177952.125\n",
            "6 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 61887.2890625\n",
            "6 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 1283.2808837890625\n",
            "6 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 134544.390625\n",
            "6 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 105761.3203125\n",
            "6 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.74\n",
            "error 4399.33984375\n",
            "Pruning layer 7...\n",
            "7 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 195075.125\n",
            "7 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 188199.59375\n",
            "7 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 68362.015625\n",
            "7 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 2055.9208984375\n",
            "7 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 148624.6875\n",
            "7 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.76\n",
            "error 118331.8828125\n",
            "7 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.73\n",
            "error 5863.21337890625\n",
            "Pruning layer 8...\n",
            "8 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 196685.578125\n",
            "8 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 191848.90625\n",
            "8 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 71549.3515625\n",
            "8 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 3229.88720703125\n",
            "8 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 152166.5625\n",
            "8 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 128388.90625\n",
            "8 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.72\n",
            "error 7272.5419921875\n",
            "Pruning layer 9...\n",
            "9 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 216710.46875\n",
            "9 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 218094.5625\n",
            "9 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 78442.7265625\n",
            "9 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 4248.8544921875\n",
            "9 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 160317.5625\n",
            "9 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 140352.75\n",
            "9 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.74\n",
            "error 8541.49609375\n",
            "Pruning layer 10...\n",
            "10 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 220507.640625\n",
            "10 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 223537.46875\n",
            "10 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 82344.2109375\n",
            "10 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 5971.28076171875\n",
            "10 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 167770.546875\n",
            "10 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 152411.0625\n",
            "10 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.66\n",
            "error 10169.05859375\n",
            "Pruning layer 11...\n",
            "11 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 235193.21875\n",
            "11 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 227953.5\n",
            "11 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 110479.84375\n",
            "11 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 6854.22265625\n",
            "11 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 183999.71875\n",
            "11 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 170350.328125\n",
            "11 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.65\n",
            "error 11351.6884765625\n",
            "Pruning layer 12...\n",
            "12 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 266638.84375\n",
            "12 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 271146.8125\n",
            "12 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 110210.7890625\n",
            "12 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 7859.3740234375\n",
            "12 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 198434.59375\n",
            "12 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.74\n",
            "error 188591.03125\n",
            "12 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.71\n",
            "error 13644.283203125\n",
            "Pruning layer 13...\n",
            "13 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 280154.625\n",
            "13 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 278565.9375\n",
            "13 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 124780.484375\n",
            "13 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 8317.53515625\n",
            "13 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 211052.15625\n",
            "13 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 206095.890625\n",
            "13 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.73\n",
            "error 17011.8359375\n",
            "Pruning layer 14...\n",
            "14 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 286005.0\n",
            "14 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 289620.40625\n",
            "14 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 125917.234375\n",
            "14 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 10528.6494140625\n",
            "14 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 234076.5625\n",
            "14 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 229280.1875\n",
            "14 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.74\n",
            "error 19963.69140625\n",
            "Pruning layer 15...\n",
            "15 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 285966.59375\n",
            "15 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.77\n",
            "error 285523.9375\n",
            "15 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 132422.890625\n",
            "15 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 11524.5986328125\n",
            "15 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 252639.046875\n",
            "15 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 248543.75\n",
            "15 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.79\n",
            "error 25181.400390625\n",
            "Pruning layer 16...\n",
            "16 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 297477.4375\n",
            "16 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 287956.875\n",
            "16 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 150748.21875\n",
            "16 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 15809.0234375\n",
            "16 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 287395.1875\n",
            "16 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 277629.3125\n",
            "16 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.67\n",
            "error 33135.7421875\n",
            "Pruning layer 17...\n",
            "17 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 302266.90625\n",
            "17 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 302206.96875\n",
            "17 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 157325.75\n",
            "17 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.72\n",
            "error 12096.607421875\n",
            "17 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.72\n",
            "error 334760.625\n",
            "17 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 314526.6875\n",
            "17 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.70\n",
            "error 36310.3828125\n",
            "Pruning layer 18...\n",
            "18 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 333032.4375\n",
            "18 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 329622.5625\n",
            "18 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 193744.578125\n",
            "18 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 13107.8515625\n",
            "18 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 380849.21875\n",
            "18 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 348689.3125\n",
            "18 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.69\n",
            "error 42822.640625\n",
            "Pruning layer 19...\n",
            "19 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 318559.9375\n",
            "19 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 311281.0\n",
            "19 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 194130.03125\n",
            "19 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 12823.537109375\n",
            "19 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 414330.25\n",
            "19 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 375328.5\n",
            "19 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.68\n",
            "error 47084.96875\n",
            "Pruning layer 20...\n",
            "20 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 324376.09375\n",
            "20 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 316015.65625\n",
            "20 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.75\n",
            "error 205394.0\n",
            "20 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 16606.5234375\n",
            "20 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 440211.5625\n",
            "20 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 392058.375\n",
            "20 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.76\n",
            "error 54861.04296875\n",
            "Pruning layer 21...\n",
            "21 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 341384.625\n",
            "21 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 324550.46875\n",
            "21 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 238490.25\n",
            "21 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 15967.3046875\n",
            "21 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.72\n",
            "error 477761.4375\n",
            "21 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 417768.6875\n",
            "21 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.78\n",
            "error 55414.234375\n",
            "Pruning layer 22...\n",
            "22 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 370660.53125\n",
            "22 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 357550.53125\n",
            "22 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 248019.59375\n",
            "22 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 20218.875\n",
            "22 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 506603.71875\n",
            "22 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 436095.4375\n",
            "22 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.75\n",
            "error 63018.609375\n",
            "Pruning layer 23...\n",
            "23 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 421356.4375\n",
            "23 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 403614.5625\n",
            "23 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 306490.84375\n",
            "23 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.75\n",
            "error 19701.13671875\n",
            "23 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 551812.375\n",
            "23 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 478886.5\n",
            "23 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.72\n",
            "error 70109.71875\n",
            "Pruning layer 24...\n",
            "24 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 364547.34375\n",
            "24 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 351450.5\n",
            "24 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 295775.8125\n",
            "24 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 23517.78125\n",
            "24 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.74\n",
            "error 580502.25\n",
            "24 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 504678.5\n",
            "24 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.67\n",
            "error 74505.125\n",
            "Pruning layer 25...\n",
            "25 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 448546.6875\n",
            "25 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 435008.90625\n",
            "25 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 369237.625\n",
            "25 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 17592.875\n",
            "25 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 627080.5625\n",
            "25 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 549079.6875\n",
            "25 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.68\n",
            "error 82139.671875\n",
            "Pruning layer 26...\n",
            "26 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 418450.25\n",
            "26 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 403619.5\n",
            "26 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 362545.125\n",
            "26 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 29749.40625\n",
            "26 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 651724.25\n",
            "26 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.75\n",
            "error 576647.875\n",
            "26 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.72\n",
            "error 89325.5546875\n",
            "Pruning layer 27...\n",
            "27 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 495388.9375\n",
            "27 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 479058.3125\n",
            "27 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 379249.375\n",
            "27 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 21182.591796875\n",
            "27 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 693576.5\n",
            "27 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 622818.4375\n",
            "27 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.73\n",
            "error 102677.453125\n",
            "Pruning layer 28...\n",
            "28 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 482919.375\n",
            "28 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 463314.125\n",
            "28 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 415945.59375\n",
            "28 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 32333.8125\n",
            "28 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 719231.75\n",
            "28 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 668145.1875\n",
            "28 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.69\n",
            "error 125288.6796875\n",
            "Pruning layer 29...\n",
            "29 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 444075.46875\n",
            "29 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 398011.21875\n",
            "29 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 394618.96875\n",
            "29 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 29610.046875\n",
            "29 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 743171.75\n",
            "29 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 703421.4375\n",
            "29 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.66\n",
            "error 154875.78125\n",
            "Pruning layer 30...\n",
            "30 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 491671.46875\n",
            "30 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 453075.03125\n",
            "30 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 443037.1875\n",
            "30 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.70\n",
            "error 32558.4609375\n",
            "30 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 754401.5\n",
            "30 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 706537.0\n",
            "30 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.69\n",
            "error 230202.03125\n",
            "Pruning layer 31...\n",
            "31 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 311125.0625\n",
            "31 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 314402.34375\n",
            "31 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 242891.25\n",
            "31 self_attn.o_proj\n",
            "Pruning ...\n",
            "time 1.67\n",
            "error 53677.04296875\n",
            "31 mlp.gate_proj\n",
            "Pruning ...\n",
            "time 1.71\n",
            "error 621239.8125\n",
            "31 mlp.up_proj\n",
            "Pruning ...\n",
            "time 1.69\n",
            "error 570409.875\n",
            "31 mlp.down_proj\n",
            "Pruning ...\n",
            "time 4.67\n",
            "error 453584.96875\n",
            "Pruning completed.\n",
            "model.embed_tokens.weight tensor(1.6411e-05)\n",
            "model.layers.0.self_attn.q_proj.weight tensor(0.6808)\n",
            "model.layers.0.self_attn.k_proj.weight tensor(0.6057)\n",
            "model.layers.0.self_attn.v_proj.weight tensor(0.5097)\n",
            "model.layers.0.self_attn.o_proj.weight tensor(0.5342)\n",
            "model.layers.0.mlp.gate_proj.weight tensor(0.5006)\n",
            "model.layers.0.mlp.up_proj.weight tensor(0.5002)\n",
            "model.layers.0.mlp.down_proj.weight tensor(0.5024)\n",
            "1058.485149860382\n",
            "Dataset: wikitext2\n",
            "Evaluating ...\n",
            "Processing layer 0\n",
            "Processing layer 1\n",
            "Processing layer 2\n",
            "Processing layer 3\n",
            "Processing layer 4\n",
            "Processing layer 5\n",
            "Processing layer 6\n",
            "Processing layer 7\n",
            "Processing layer 8\n",
            "Processing layer 9\n",
            "Processing layer 10\n",
            "Processing layer 11\n",
            "Processing layer 12\n",
            "Processing layer 13\n",
            "Processing layer 14\n",
            "Processing layer 15\n",
            "Processing layer 16\n",
            "Processing layer 17\n",
            "Processing layer 18\n",
            "Processing layer 19\n",
            "Processing layer 20\n",
            "Processing layer 21\n",
            "Processing layer 22\n",
            "Processing layer 23\n",
            "Processing layer 24\n",
            "Processing layer 25\n",
            "Processing layer 26\n",
            "Processing layer 27\n",
            "Processing layer 28\n",
            "Processing layer 29\n",
            "Processing layer 30\n",
            "Processing layer 31\n",
            "Perplexity: 7.006\n",
            "Dataset: ptb\n",
            "Evaluating ...\n",
            "Processing layer 0\n",
            "Processing layer 1\n",
            "Processing layer 2\n",
            "Processing layer 3\n",
            "Processing layer 4\n",
            "Processing layer 5\n",
            "Processing layer 6\n",
            "Processing layer 7\n",
            "Processing layer 8\n",
            "Processing layer 9\n",
            "Processing layer 10\n",
            "Processing layer 11\n",
            "Processing layer 12\n",
            "Processing layer 13\n",
            "Processing layer 14\n",
            "Processing layer 15\n",
            "Processing layer 16\n",
            "Processing layer 17\n",
            "Processing layer 18\n",
            "Processing layer 19\n",
            "Processing layer 20\n",
            "Processing layer 21\n",
            "Processing layer 22\n",
            "Processing layer 23\n",
            "Processing layer 24\n",
            "Processing layer 25\n",
            "Processing layer 26\n",
            "Processing layer 27\n",
            "Processing layer 28\n",
            "Processing layer 29\n",
            "Processing layer 30\n",
            "Processing layer 31\n",
            "Perplexity: 69852.914\n",
            "Dataset: c4\n",
            "Evaluating ...\n",
            "Processing layer 0\n",
            "Processing layer 1\n",
            "Processing layer 2\n",
            "Processing layer 3\n",
            "Processing layer 4\n",
            "Processing layer 5\n",
            "Processing layer 6\n",
            "Processing layer 7\n",
            "Processing layer 8\n",
            "Processing layer 9\n",
            "Processing layer 10\n",
            "Processing layer 11\n",
            "Processing layer 12\n",
            "Processing layer 13\n",
            "Processing layer 14\n",
            "Processing layer 15\n",
            "Processing layer 16\n",
            "Processing layer 17\n",
            "Processing layer 18\n",
            "Processing layer 19\n",
            "Processing layer 20\n",
            "Processing layer 21\n",
            "Processing layer 22\n",
            "Processing layer 23\n",
            "Processing layer 24\n",
            "Processing layer 25\n",
            "Processing layer 26\n",
            "Processing layer 27\n",
            "Processing layer 28\n",
            "Processing layer 29\n",
            "Processing layer 30\n",
            "Processing layer 31\n",
            "Perplexity: 9.574\n"
          ]
        }
      ],
      "source": [
        "!python llama_sparseqjl.py --model_name \"meta-llama/Llama-2-7b-hf\" \\\n",
        "    --qjl \\\n",
        "    --sparsity 0.5 \\\n",
        "    --wbits 4 \\\n",
        "    --dtype \"float16\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkNo7WPwdOw-"
      },
      "source": [
        "## Test SparseQJL on OPT\n",
        "Params:\n",
        "\n",
        "* `model_name`: String denoting HuggingFace OPT model path to test. Default: `facebook/opt-125m`\n",
        "* `qjl`: Boolean flag denoting whether or not to apply QJL.\n",
        "* `sparsity`: Float between 0 and 1 denoting \\% uniform sparsity with SparseGPT. Default: `0.0`\n",
        "* `wbits`: Int denoting the bit-width for weight quantization. We suggest using a value of `4`. Default: `16` (No quant)\n",
        "* `dtype`: String denoting standard datatype of model. Options are `float16` and `float32`. Default: `float16`.\n",
        "\n",
        "Note:\n",
        "\n",
        "* Currently, our implementation of SparseQJL on OPT is still not 100\\% refined, hence the extremely high perplexity scores. We will continue to resolve the issue and make updates to this repo.\n",
        "* When prompted to run custom code, answer `y` in the CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aiEP6KB2JIQ",
        "outputId": "0dd7853a-fb6c-4db5-b0f5-bd06c3002846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-21 02:45:47.624566: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-21 02:45:47.641813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 02:45:47.662526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 02:45:47.668804: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 02:45:47.683915: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 02:45:48.974277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 644/644 [00:00<00:00, 3.99MB/s]\n",
            "tokenizer_config.json: 100% 685/685 [00:00<00:00, 4.80MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 1.42MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.04MB/s]\n",
            "special_tokens_map.json: 100% 441/441 [00:00<00:00, 3.10MB/s]\n",
            "pytorch_model.bin: 100% 663M/663M [00:02<00:00, 241MB/s]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 931kB/s]\n",
            "Model and tokenizer for facebook/opt-350m are set up successfully.\n",
            "model.safetensors: 100% 662M/662M [00:27<00:00, 24.5MB/s]\n",
            "Starting ...\n",
            "Ready.\n",
            "0 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.57\n",
            "error 6172.08984375\n",
            "0 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 26.651397705078125\n",
            "0 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 1860.9913330078125\n",
            "0 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 0.04018867015838623\n",
            "0 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 176034.78125\n",
            "0 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 2018.353759765625\n",
            "1 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 43100.51953125\n",
            "1 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 19974.869140625\n",
            "1 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 46433.5859375\n",
            "1 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 571.875732421875\n",
            "1 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 193080.3125\n",
            "1 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 2197.54833984375\n",
            "2 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 64953.96484375\n",
            "2 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 28994.40234375\n",
            "2 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 67357.9140625\n",
            "2 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 677.9827880859375\n",
            "2 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 206682.046875\n",
            "2 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 2705.5302734375\n",
            "3 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 71988.890625\n",
            "3 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 36299.16796875\n",
            "3 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 74597.3125\n",
            "3 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 682.3972778320312\n",
            "3 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 212776.296875\n",
            "3 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 3098.977294921875\n",
            "4 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 75801.1328125\n",
            "4 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 34656.0625\n",
            "4 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 79700.1015625\n",
            "4 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 840.9681396484375\n",
            "4 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 218863.640625\n",
            "4 fc2\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 3399.59326171875\n",
            "5 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 54413.6171875\n",
            "5 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 33518.734375\n",
            "5 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 58000.73828125\n",
            "5 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 593.0463256835938\n",
            "5 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 224715.84375\n",
            "5 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 3374.33837890625\n",
            "6 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 56914.03125\n",
            "6 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 29213.482421875\n",
            "6 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 63678.8203125\n",
            "6 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 1136.2403564453125\n",
            "6 fc1\n",
            "Pruning ...\n",
            "time 0.42\n",
            "error 239188.234375\n",
            "6 fc2\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 3920.376220703125\n",
            "7 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 67481.09375\n",
            "7 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 33365.5\n",
            "7 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 74827.6015625\n",
            "7 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 1848.9891357421875\n",
            "7 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 261030.421875\n",
            "7 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 4966.568359375\n",
            "8 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 84346.09375\n",
            "8 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 36161.3671875\n",
            "8 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 94089.96875\n",
            "8 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2620.02783203125\n",
            "8 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 259109.25\n",
            "8 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 6664.31103515625\n",
            "9 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 94820.7578125\n",
            "9 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 39478.51171875\n",
            "9 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 106716.859375\n",
            "9 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 2717.662841796875\n",
            "9 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 256665.71875\n",
            "9 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 6628.19873046875\n",
            "10 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 96621.703125\n",
            "10 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 48562.92578125\n",
            "10 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.44\n",
            "error 101677.6640625\n",
            "10 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 3868.95703125\n",
            "10 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 279211.53125\n",
            "10 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 7033.1796875\n",
            "11 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 89252.9375\n",
            "11 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 57772.0546875\n",
            "11 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.44\n",
            "error 94515.375\n",
            "11 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.42\n",
            "error 2951.9580078125\n",
            "11 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 283412.3125\n",
            "11 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 8116.416015625\n",
            "12 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 95595.0625\n",
            "12 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 69890.921875\n",
            "12 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 100432.9453125\n",
            "12 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 4904.81201171875\n",
            "12 fc1\n",
            "Pruning ...\n",
            "time 0.43\n",
            "error 304263.5625\n",
            "12 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 8037.9560546875\n",
            "13 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 96283.6875\n",
            "13 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 69620.84375\n",
            "13 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 100794.5703125\n",
            "13 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 4824.3779296875\n",
            "13 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 303061.40625\n",
            "13 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 8883.4580078125\n",
            "14 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 105415.578125\n",
            "14 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 77230.265625\n",
            "14 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 110560.5390625\n",
            "14 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2912.060546875\n",
            "14 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 297409.625\n",
            "14 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 8036.9873046875\n",
            "15 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 104286.921875\n",
            "15 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 70640.6640625\n",
            "15 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 109315.46875\n",
            "15 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 2182.93701171875\n",
            "15 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 289839.1875\n",
            "15 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 7720.4951171875\n",
            "16 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 105110.65625\n",
            "16 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 75795.546875\n",
            "16 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 109817.9296875\n",
            "16 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2763.89453125\n",
            "16 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 276325.4375\n",
            "16 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 7347.6240234375\n",
            "17 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 99394.515625\n",
            "17 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.44\n",
            "error 70805.90625\n",
            "17 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 104287.046875\n",
            "17 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2234.274169921875\n",
            "17 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 267065.46875\n",
            "17 fc2\n",
            "Pruning ...\n",
            "time 1.60\n",
            "error 6810.8251953125\n",
            "18 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 92465.796875\n",
            "18 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 69590.828125\n",
            "18 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 98343.828125\n",
            "18 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2016.6629638671875\n",
            "18 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 246003.59375\n",
            "18 fc2\n",
            "Pruning ...\n",
            "time 1.60\n",
            "error 6012.88037109375\n",
            "19 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 88383.28125\n",
            "19 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 54901.07421875\n",
            "19 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 93287.9921875\n",
            "19 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 2525.5703125\n",
            "19 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 230630.921875\n",
            "19 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 5264.18408203125\n",
            "20 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 73592.328125\n",
            "20 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 48615.00390625\n",
            "20 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 85315.390625\n",
            "20 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 3725.6552734375\n",
            "20 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 238974.6875\n",
            "20 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 5538.9072265625\n",
            "21 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 75623.3984375\n",
            "21 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 49768.109375\n",
            "21 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 95158.7265625\n",
            "21 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 4014.782958984375\n",
            "21 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 242834.921875\n",
            "21 fc2\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 6460.71337890625\n",
            "22 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 83679.6640625\n",
            "22 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 53727.7265625\n",
            "22 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 123029.953125\n",
            "22 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 6641.8193359375\n",
            "22 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 226168.34375\n",
            "22 fc2\n",
            "Pruning ...\n",
            "time 1.64\n",
            "error 8044.5849609375\n",
            "23 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 87711.125\n",
            "23 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 75113.359375\n",
            "23 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 99507.90625\n",
            "23 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 7273.94384765625\n",
            "23 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 185229.09375\n",
            "23 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 5376.7705078125\n",
            "model.decoder.embed_tokens.weight tensor(5.8277e-07)\n",
            "model.decoder.embed_positions.weight tensor(0.0005)\n",
            "model.decoder.project_out.weight tensor(0.)\n",
            "model.decoder.project_in.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn.k_proj.weight tensor(0.5005)\n",
            "model.decoder.layers.0.self_attn.k_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight tensor(0.5004)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.q_proj.weight tensor(0.5003)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.out_proj.weight tensor(0.5021)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias tensor(0.)\n",
            "model.decoder.layers.0.fc1.weight tensor(0.5002)\n",
            "model.decoder.layers.0.fc1.bias tensor(0.)\n",
            "model.decoder.layers.0.fc2.weight tensor(0.5001)\n",
            "131.42604637145996\n",
            "wikitext2\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "Perplexity: 34.493584\n",
            "ptb\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "Perplexity: 46.588585\n",
            "c4\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "Perplexity: 31.108746\n"
          ]
        }
      ],
      "source": [
        "!python opt_sparseqjl.py --model_name \"facebook/opt-350m\" \\\n",
        "    --qjl \\\n",
        "    --sparsity 0.5 \\\n",
        "    --wbits 4 \\\n",
        "    --dtype \"float16\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
